{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Kokoro-82M TTS - Fast High-Quality Text-to-Speech\n",
    "\n",
    "This notebook demonstrates Kokoro-82M TTS, which balances speed and quality with only 82M parameters.\n",
    "\n",
    "**Features:**\n",
    "- Fast generation (~5-10 seconds)\n",
    "- High quality despite small size (82M parameters)\n",
    "- Apache licensed and cost-efficient\n",
    "- Apple Silicon GPU optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T07:27:26.107322Z",
     "iopub.status.busy": "2025-05-23T07:27:26.107099Z",
     "iopub.status.idle": "2025-05-23T07:27:27.231067Z",
     "shell.execute_reply": "2025-05-23T07:27:27.230782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Loading Kokoro-82M TTS model via transformers...\n"
     ]
    }
   ],
   "source": [
    "# Load Kokoro TTS model\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(\"Loading Kokoro-82M TTS model via transformers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T07:27:27.249249Z",
     "iopub.status.busy": "2025-05-23T07:27:27.248972Z",
     "iopub.status.idle": "2025-05-23T07:27:28.696918Z",
     "shell.execute_reply": "2025-05-23T07:27:28.696620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Kokoro-82M TTS model...\n",
      "Transformers pipeline not available: Unrecognized model in hexgrad/Kokoro-82M. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n",
      "Kokoro-82M requires specific installation - see model card for details\n",
      "Load attempt completed in 0.29 seconds\n",
      "Model size: 82M parameters (lightweight but high quality)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Kokoro pipeline via Hugging Face transformers\n",
    "print(\"Loading Kokoro-82M TTS model...\")\n",
    "start_load = time.time()\n",
    "\n",
    "# Try to use the Kokoro model via transformers\n",
    "# Note: As of now, Kokoro may not be directly available via transformers pipeline\n",
    "# This is a placeholder implementation - we may need to use the model directly\n",
    "try:\n",
    "    # Attempt to load via transformers pipeline\n",
    "    kokoro_pipe = pipeline(\"text-to-speech\", model=\"hexgrad/Kokoro-82M\")\n",
    "    print(\"Loaded via transformers pipeline\")\n",
    "except Exception as e:\n",
    "    print(f\"Transformers pipeline not available: {e}\")\n",
    "    print(\"Kokoro-82M requires specific installation - see model card for details\")\n",
    "    kokoro_pipe = None\n",
    "\n",
    "end_load = time.time()\n",
    "print(f\"Load attempt completed in {end_load - start_load:.2f} seconds\")\n",
    "print(\"Model size: 82M parameters (lightweight but high quality)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T07:27:28.698298Z",
     "iopub.status.busy": "2025-05-23T07:27:28.698188Z",
     "iopub.status.idle": "2025-05-23T07:27:28.701707Z",
     "shell.execute_reply": "2025-05-23T07:27:28.701485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokoro model not available - skipping generation\n",
      "To use Kokoro-82M, install: pip install kokoro>=0.9.2\n"
     ]
    }
   ],
   "source": [
    "# Generate speech with Kokoro-82M (if available)\n",
    "text = \"Hello, this is Kokoro TTS. I provide fast, high-quality speech generation with only 82 million parameters.\"\n",
    "\n",
    "if kokoro_pipe is not None:\n",
    "    print(\"Generating audio with Kokoro-82M...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Generate audio\n",
    "    audio_data = kokoro_pipe(text)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Audio generated in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Audio type: {type(audio_data)}\")\n",
    "    if hasattr(audio_data, 'shape'):\n",
    "        print(f\"Audio shape: {audio_data.shape}\")\n",
    "    elif isinstance(audio_data, dict) and 'audio' in audio_data:\n",
    "        print(f\"Audio shape: {audio_data['audio'].shape}\")\n",
    "\n",
    "    # Get sample rate\n",
    "    if isinstance(audio_data, dict) and 'sampling_rate' in audio_data:\n",
    "        sample_rate = audio_data['sampling_rate']\n",
    "    else:\n",
    "        sample_rate = 24000  # Default for Kokoro\n",
    "    print(f\"Sample rate: {sample_rate}\")\n",
    "else:\n",
    "    print(\"Kokoro model not available - skipping generation\")\n",
    "    print(\"To use Kokoro-82M, install: pip install kokoro>=0.9.2\")\n",
    "    audio_data = None\n",
    "    sample_rate = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T07:27:28.702926Z",
     "iopub.status.busy": "2025-05-23T07:27:28.702837Z",
     "iopub.status.idle": "2025-05-23T07:27:28.715130Z",
     "shell.execute_reply": "2025-05-23T07:27:28.714853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No audio generated - Kokoro model not available\n",
      "\n",
      "To install Kokoro-82M:\n",
      "1. pip install kokoro>=0.9.2\n",
      "2. Restart notebook and try again\n"
     ]
    }
   ],
   "source": [
    "# Save Kokoro audio as MP3 (if available)\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "if audio_data is not None:\n",
    "    # Create output directory\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "    # Save as WAV first\n",
    "    wav_file = \"output/kokoro_output.wav\"\n",
    "    mp3_file = \"output/kokoro_output.mp3\"\n",
    "\n",
    "    # Extract audio array\n",
    "    if isinstance(audio_data, dict) and 'audio' in audio_data:\n",
    "        audio_array = audio_data['audio']\n",
    "    else:\n",
    "        audio_array = audio_data\n",
    "\n",
    "    # Convert to numpy array if needed\n",
    "    if torch.is_tensor(audio_array):\n",
    "        audio_array = audio_array.cpu().numpy()\n",
    "    else:\n",
    "        audio_array = np.array(audio_array)\n",
    "\n",
    "    # Ensure 1D array\n",
    "    if audio_array.ndim > 1:\n",
    "        audio_array = audio_array.squeeze()\n",
    "\n",
    "    # Normalize audio to prevent clipping\n",
    "    audio_normalized = audio_array / np.max(np.abs(audio_array))\n",
    "\n",
    "    # Save as WAV\n",
    "    sf.write(wav_file, audio_normalized, sample_rate)\n",
    "\n",
    "    # Convert to MP3\n",
    "    audio_segment = AudioSegment.from_wav(wav_file)\n",
    "    audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "    print(f\"Kokoro audio saved as {mp3_file}\")\n",
    "    print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")\n",
    "    print(f\"Generation time: {end_time - start_time:.2f} seconds\")\n",
    "    print(\"\\n⚡ Kokoro-82M TTS: Perfect balance of speed and quality!\")\n",
    "else:\n",
    "    print(\"No audio generated - Kokoro model not available\")\n",
    "    print(\"\\nTo install Kokoro-82M:\")\n",
    "    print(\"1. pip install kokoro>=0.9.2\")\n",
    "    print(\"2. Restart notebook and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0820caa5c7634a1999bdf66879437af3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d29ea8b4fbe84d6c91839e4ee54acc63",
       "max": 2351,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_12909c6a57fd471cbe74759eaaca27f0",
       "tabbable": null,
       "tooltip": null,
       "value": 2351
      }
     },
     "12909c6a57fd471cbe74759eaaca27f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "386749c6bc504269a0e0101fdd3b1be2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4d798e40d5994fe7b90212ab692acc71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50653c7060f74135a00958af934e308b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54a7632d08f14fb08969419ec4bdaa4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8c32227e1dfe46c3b67d967affce694f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d798e40d5994fe7b90212ab692acc71",
       "placeholder": "​",
       "style": "IPY_MODEL_386749c6bc504269a0e0101fdd3b1be2",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.35k/2.35k [00:00&lt;00:00, 274kB/s]"
      }
     },
     "d29ea8b4fbe84d6c91839e4ee54acc63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9082a5d7a2c48bbba45d9da77a4cdcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dafe4c08fd80447ab054f43c65a28ba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fb846deb25dd467a84cc44450276a88f",
        "IPY_MODEL_0820caa5c7634a1999bdf66879437af3",
        "IPY_MODEL_8c32227e1dfe46c3b67d967affce694f"
       ],
       "layout": "IPY_MODEL_d9082a5d7a2c48bbba45d9da77a4cdcf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fb846deb25dd467a84cc44450276a88f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_50653c7060f74135a00958af934e308b",
       "placeholder": "​",
       "style": "IPY_MODEL_54a7632d08f14fb08969419ec4bdaa4c",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
