{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bark TTS - High Quality Text-to-Speech\n",
    "\n",
    "This notebook demonstrates Bark TTS, which produces the most human-like speech but is slower (~40 seconds generation time).\n",
    "\n",
    "**Features:**\n",
    "- Excellent quality and naturalness\n",
    "- Runs on CPU (MPS has compatibility issues)\n",
    "- ~40 seconds generation time\n",
    "- Large model size (~1B+ parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Loading Bark TTS on Apple Silicon GPU...\n"
     ]
    }
   ],
   "source": [
    "# Load Bark TTS model on Apple Silicon GPU\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Enable MPS fallback for compatibility\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(\"Loading Bark TTS on Apple Silicon GPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgenii/code/python/txt_to_speach/.venv/lib/python3.13/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bark TTS loaded successfully on CPU!\n",
      "Note: Running on CPU due to MPS dtype compatibility issues\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bark pipeline on CPU (due to MPS compatibility issues)\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\", device=\"cpu\")\n",
    "print(\"Bark TTS loaded successfully on CPU!\")\n",
    "print(\"Note: Running on CPU due to MPS dtype compatibility issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio generated in 93.27 seconds\n",
      "Sample rate: 24000\n",
      "Audio shape: (1, 333120)\n"
     ]
    }
   ],
   "source": [
    "# Generate speech with Bark TTS\n",
    "import time\n",
    "\n",
    "text = \"Hello, this is Bark TTS. I produce the most natural and human-like speech, though I take a bit longer to generate.\"\n",
    "\n",
    "start_time = time.time()\n",
    "speech = pipe(text)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Audio generated in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Sample rate: {speech['sampling_rate']}\")\n",
    "print(f\"Audio shape: {speech['audio'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bark audio saved as output/bark_output.mp3\n",
      "Duration: 13.88 seconds\n",
      "Generation time: 93.27 seconds\n",
      "\n",
      "ðŸŽ­ Bark TTS: Best quality, human-like speech!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Save Bark audio as MP3\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save as WAV first\n",
    "wav_file = \"output/bark_output.wav\"\n",
    "mp3_file = \"output/bark_output.mp3\"\n",
    "\n",
    "# Normalize audio to prevent clipping\n",
    "audio_normalized = speech['audio'].squeeze() / np.max(np.abs(speech['audio'].squeeze()))\n",
    "\n",
    "# Save as WAV\n",
    "sf.write(wav_file, audio_normalized, speech['sampling_rate'])\n",
    "\n",
    "# Convert to MP3\n",
    "audio_segment = AudioSegment.from_wav(wav_file)\n",
    "audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "print(f\"Bark audio saved as {mp3_file}\")\n",
    "print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")\n",
    "print(f\"Generation time: {end_time - start_time:.2f} seconds\")\n",
    "print(\"\\nðŸŽ­ Bark TTS: Best quality, human-like speech!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
