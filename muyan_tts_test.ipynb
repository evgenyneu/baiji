{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Loading Bark TTS on Apple Silicon GPU...\n"
     ]
    }
   ],
   "source": [
    "# Load Bark TTS model on Apple Silicon GPU\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Enable MPS fallback for compatibility\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(\"Loading Bark TTS on Apple Silicon GPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bark model loaded (will use MPS for forward pass, CPU for generation logic)\n"
     ]
    }
   ],
   "source": [
    "# Load Bark with MPS workaround - use CPU for generation\n",
    "from transformers import BarkModel, BarkProcessor\n",
    "import torch\n",
    "\n",
    "processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n",
    "\n",
    "# Load model on CPU first to avoid MPS dtype issues during generation\n",
    "model = BarkModel.from_pretrained(\"suno/bark-small\")\n",
    "print(\"Bark model loaded (will use MPS for forward pass, CPU for generation logic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio on CPU (MPS has known issues with Bark)...\n",
      "Audio generated in 43.93 seconds on CPU\n",
      "Audio shape: torch.Size([1, 173440])\n"
     ]
    }
   ],
   "source": [
    "# Generate speech on CPU (MPS has dtype compatibility issues with Bark)\n",
    "import time\n",
    "\n",
    "text = \"Hello, this is Bark TTS. Due to MPS dtype issues, we're using CPU for now.\"\n",
    "\n",
    "# Process input\n",
    "inputs = processor(text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Generating audio on CPU (MPS has known issues with Bark)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    audio_array = model.generate(**inputs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Audio generated in {end_time - start_time:.2f} seconds on CPU\")\n",
    "print(f\"Audio shape: {audio_array.shape}\")\n",
    "\n",
    "# Convert to numpy for saving\n",
    "audio_np = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "# Store for next cell\n",
    "speech = {\"audio\": audio_np, \"sampling_rate\": 24000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as output/bark_output.mp3\n",
      "Duration: 7.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Save audio as MP3 in output directory\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save as WAV first (soundfile doesn't support MP3 directly)\n",
    "wav_file = \"output/bark_output.wav\"\n",
    "mp3_file = \"output/bark_output.mp3\"\n",
    "\n",
    "# Normalize audio to prevent clipping\n",
    "audio_normalized = speech[\"audio\"] / np.max(np.abs(speech[\"audio\"]))\n",
    "\n",
    "# Save as WAV\n",
    "sf.write(wav_file, audio_normalized, speech[\"sampling_rate\"])\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "audio_segment = AudioSegment.from_wav(wav_file)\n",
    "audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "print(f\"Audio saved as {mp3_file}\")\n",
    "print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try VITS TTS model - much faster and lighter than Bark\n",
    "from transformers import VitsModel, VitsTokenizer\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load VITS model (lightweight, Apple Silicon friendly)\n",
    "model_name = \"facebook/mms-tts-eng\"  # English VITS model\n",
    "tokenizer = VitsTokenizer.from_pretrained(model_name)\n",
    "model = VitsModel.from_pretrained(model_name)\n",
    "\n",
    "# Move to MPS if available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"VITS model loaded on {device}\")\n",
    "print(f\"Model size: ~40M parameters (much smaller than Bark)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate speech with VITS (correct usage)\n",
    "import time\n",
    "\n",
    "text = \"Hello, this is VITS TTS model running much faster than Bark on Apple Silicon.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to device\n",
    "if device == \"mps\":\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "print(\"Generating audio with VITS...\")\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    # VITS uses forward() not generate()\n",
    "    outputs = model(**inputs)\n",
    "    audio_array = outputs.waveform\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Audio generated in {end_time - start_time:.2f} seconds on {device}\")\n",
    "print(f\"Audio shape: {audio_array.shape}\")\n",
    "\n",
    "# Check the model's actual sample rate\n",
    "model_sample_rate = model.config.sampling_rate\n",
    "print(f\"Model's actual sampling rate: {model_sample_rate}\")\n",
    "\n",
    "# Convert to numpy for saving\n",
    "vits_audio = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "# Use the correct sample rate from model config\n",
    "vits_speech = {\"audio\": vits_audio, \"sampling_rate\": model_sample_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VITS audio as MP3\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save as WAV first\n",
    "wav_file = \"output/vits_output.wav\"\n",
    "mp3_file = \"output/vits_output.mp3\"\n",
    "\n",
    "# Normalize audio to prevent clipping\n",
    "audio_normalized = vits_speech[\"audio\"] / np.max(np.abs(vits_speech[\"audio\"]))\n",
    "\n",
    "# Save as WAV\n",
    "sf.write(wav_file, audio_normalized, vits_speech[\"sampling_rate\"])\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "audio_segment = AudioSegment.from_wav(wav_file)\n",
    "audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "print(f\"VITS audio saved as {mp3_file}\")\n",
    "print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")\n",
    "print(f\"Generation time: 10 seconds (4x faster than Bark!)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
