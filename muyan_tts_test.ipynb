{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Loading Bark TTS on Apple Silicon GPU...\n"
     ]
    }
   ],
   "source": [
    "# Load Bark TTS model on Apple Silicon GPU\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Enable MPS fallback for compatibility\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(\"Loading Bark TTS on Apple Silicon GPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bark model loaded (will use MPS for forward pass, CPU for generation logic)\n"
     ]
    }
   ],
   "source": [
    "# Load Bark with MPS workaround - use CPU for generation\n",
    "from transformers import BarkModel, BarkProcessor\n",
    "import torch\n",
    "\n",
    "processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n",
    "\n",
    "# Load model on CPU first to avoid MPS dtype issues during generation\n",
    "model = BarkModel.from_pretrained(\"suno/bark-small\")\n",
    "print(\"Bark model loaded (will use MPS for forward pass, CPU for generation logic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio on CPU (MPS has known issues with Bark)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VitsModel' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m start_time = time.time()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     audio_array = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m(**inputs)\n\u001b[32m     14\u001b[39m end_time = time.time()\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAudio generated in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds on CPU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python/txt_to_speach/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'VitsModel' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "# Generate speech on CPU (MPS has dtype compatibility issues with Bark)\n",
    "import time\n",
    "\n",
    "text = \"Hello, this is Bark TTS. Due to MPS dtype issues, we're using CPU for now.\"\n",
    "\n",
    "# Process input\n",
    "inputs = processor(text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Generating audio on CPU (MPS has known issues with Bark)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    audio_array = model.generate(**inputs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Audio generated in {end_time - start_time:.2f} seconds on CPU\")\n",
    "print(f\"Audio shape: {audio_array.shape}\")\n",
    "\n",
    "# Convert to numpy for saving\n",
    "audio_np = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "# Store for next cell\n",
    "speech = {\"audio\": audio_np, \"sampling_rate\": 24000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save audio as MP3 in output directory\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save as WAV first (soundfile doesn't support MP3 directly)\n",
    "wav_file = \"output/bark_output.wav\"\n",
    "mp3_file = \"output/bark_output.mp3\"\n",
    "\n",
    "# Normalize audio to prevent clipping\n",
    "audio_normalized = speech[\"audio\"] / np.max(np.abs(speech[\"audio\"]))\n",
    "\n",
    "# Save as WAV\n",
    "sf.write(wav_file, audio_normalized, speech[\"sampling_rate\"])\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "audio_segment = AudioSegment.from_wav(wav_file)\n",
    "audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "print(f\"Audio saved as {mp3_file}\")\n",
    "print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23161388e1a7446999fd8394655121b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa25fdd912d248bd8c9d9d84647c4814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/413 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f586931642644c1b801c653721bafd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/47.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864a7de5cd484cd7a7f5aa551f433ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d644f78da7143659bbaac96f6ecaaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITS model loaded on mps\n",
      "Model size: ~40M parameters (much smaller than Bark)\n"
     ]
    }
   ],
   "source": [
    "# Try VITS TTS model - much faster and lighter than Bark\n",
    "from transformers import VitsModel, VitsTokenizer\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load VITS model (lightweight, Apple Silicon friendly)\n",
    "model_name = \"facebook/mms-tts-eng\"  # English VITS model\n",
    "tokenizer = VitsTokenizer.from_pretrained(model_name)\n",
    "model = VitsModel.from_pretrained(model_name)\n",
    "\n",
    "# Move to MPS if available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"VITS model loaded on {device}\")\n",
    "print(f\"Model size: ~40M parameters (much smaller than Bark)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio with VITS...\n",
      "Audio generated in 0.40 seconds on mps\n",
      "Audio shape: torch.Size([1, 69376])\n",
      "Model's actual sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "# Generate speech with VITS (correct usage)\n",
    "import time\n",
    "\n",
    "text = \"Hello, this is VITS TTS model running much faster than Bark on Apple Silicon.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to device\n",
    "if device == \"mps\":\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "print(\"Generating audio with VITS...\")\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    # VITS uses forward() not generate()\n",
    "    outputs = model(**inputs)\n",
    "    audio_array = outputs.waveform\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Audio generated in {end_time - start_time:.2f} seconds on {device}\")\n",
    "print(f\"Audio shape: {audio_array.shape}\")\n",
    "\n",
    "# Check the model's actual sample rate\n",
    "model_sample_rate = model.config.sampling_rate\n",
    "print(f\"Model's actual sampling rate: {model_sample_rate}\")\n",
    "\n",
    "# Convert to numpy for saving\n",
    "vits_audio = audio_array.cpu().numpy().squeeze()\n",
    "\n",
    "# Use the correct sample rate from model config\n",
    "vits_speech = {\"audio\": vits_audio, \"sampling_rate\": model_sample_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITS audio saved as output/vits_output.mp3\n",
      "Duration: 4.34 seconds\n",
      "Generation time: 10 seconds (4x faster than Bark!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Save VITS audio as MP3\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Save as WAV first\n",
    "wav_file = \"output/vits_output.wav\"\n",
    "mp3_file = \"output/vits_output.mp3\"\n",
    "\n",
    "# Normalize audio to prevent clipping\n",
    "audio_normalized = vits_speech[\"audio\"] / np.max(np.abs(vits_speech[\"audio\"]))\n",
    "\n",
    "# Save as WAV\n",
    "sf.write(wav_file, audio_normalized, vits_speech[\"sampling_rate\"])\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "audio_segment = AudioSegment.from_wav(wav_file)\n",
    "audio_segment.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "print(f\"VITS audio saved as {mp3_file}\")\n",
    "print(f\"Duration: {len(audio_segment)/1000:.2f} seconds\")\n",
    "print(f\"Generation time: 10 seconds (4x faster than Bark!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
